{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import baselines as b\n",
    "import torch\n",
    "from torch_models import load_models, BinaryClassifier, MultiClassifier, try_region_multi\n",
    "from attacks import try_region_binary, distributional_oracle_multi, distributional_oracle_binary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_budget = 1.3 # Multiclass noise budget\n",
    "# noise_budget =2.3 # Binary noise budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dirs = {'binary_oracle': 'experiment_results/binary_oracle_1/',\n",
    "#             'binary_pgd': 'experiment_results/binary_pgd_1/' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dirs = {'multi_oracle': 'experiment_results/multi_oracle_1/',\n",
    "            'multi_pgd': 'experiment_results/multi_pgd_1/' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_results(exp_dirs):\n",
    "    exp_results = dict()\n",
    "    for name, exp_dir in exp_dirs.items():\n",
    "        results = dict()\n",
    "        results['noise_vectors'] = torch.load(exp_dir + 'noise_vectors.pt')\n",
    "        results['expected_losses'] = np.load(exp_dir + 'expected_losses.npy')\n",
    "        results['minimum_losses'] = np.load(exp_dir + 'minimum_losses.npy')\n",
    "        exp_results[name] = results\n",
    "    return exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = load_experiment_results(exp_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = 'experiment_data/linear/binary/'\n",
    "data_folder = 'experiment_data/linear/multi/'\n",
    "images = torch.load(data_folder + 'mnist_images.pt')\n",
    "labels = torch.load(data_folder + 'mnist_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanky/miniconda3/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch_models.MultiClassifier' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# models = load_models('mnist_binary')\n",
    "models = load_models('mnist_multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print([model.accuracy(images, labels) for model in models])\n",
    "ensemble = ensemble_linear_models(models)\n",
    "print(ensemble.accuracy(images, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_feasible_models(models, x, noise_budget):\n",
    "    dists = [model.distance(x).item() for model in models]\n",
    "    num_models = len(models)\n",
    "    return [models[i] for i in range(num_models) if dists[i] < noise_budget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_linear_models(models):\n",
    "    num_classifiers = len(models)\n",
    "    model_type = type(models[0])\n",
    "    if model_type is BinaryClassifier:\n",
    "        TorchModel = BinaryClassifier\n",
    "        ensemble_weights = sum([1.0 / num_classifiers * model.weights.reshape(1, -1)\n",
    "                                for model in models])\n",
    "\n",
    "    else:\n",
    "        TorchModel = MultiClassifier\n",
    "        ensemble_weights = sum([1.0 / num_classifiers * model.weights\n",
    "                                for model in models])\n",
    "\n",
    "    ensemble_bias = sum([1.0 / num_classifiers * model.bias for model in models])\n",
    "    ensemble_weights = torch.tensor(ensemble_weights, dtype=torch.float)\n",
    "    ensemble_bias = torch.tensor(ensemble_bias, dtype=torch.float)\n",
    "    ensemble = TorchModel(ensemble_weights, ensemble_bias)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def compute_linear_ensemble_baseline(models, images, labels, noise_budget):\n",
    "    model_type = type(models[0])\n",
    "    if model_type is BinaryClassifier:\n",
    "        oracle = distributional_oracle_binary\n",
    "        out_dim = 1\n",
    "    else:\n",
    "        oracle = distributional_oracle_multi\n",
    "        out_dim = 3\n",
    "\n",
    "    noise_vectors = []\n",
    "    for i in range(len(images)):\n",
    "        x = images[i].unsqueeze(0)\n",
    "        y = labels[i]\n",
    "        ensemble = ensemble_linear_models(subset_feasible_models(models, x, noise_budget))\n",
    "        ensemble_array = [(torch.tensor(ensemble.weights.reshape(out_dim, -1),\n",
    "                                        dtype=torch.float),\n",
    "                           torch.tensor(ensemble.bias, dtype=torch.float))]\n",
    "\n",
    "        v = oracle(np.ones(1), ensemble_array, x, y, sys.maxsize)\n",
    "        v = v / v.norm() * noise_budget\n",
    "        noise_vectors.append(v)\n",
    "    return torch.stack(noise_vectors).reshape(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_noise_vectors = compute_linear_ensemble_baseline(models, images, labels, noise_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3000001907348633"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([v.norm().item() for v in ensemble_noise_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_accs_per_point = b.compute_model_accs_per_point(models, images, ensemble_noise_vectors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Baseline\n",
      "Mean  0.314 Max  0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble Baseline\")\n",
    "print(\"Mean \", np.mean(np.mean(ensemble_accs_per_point, axis=1)), \n",
    "      \"Max \", np.mean(np.max(ensemble_accs_per_point, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Individual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_individual_baseline(models, images, labels, noise_budget):\n",
    "    \n",
    "    model_type = type(models[0])\n",
    "    if model_type is BinaryClassifier:\n",
    "        oracle = distributional_oracle_binary\n",
    "        out_dim = 1\n",
    "    else:\n",
    "        oracle = distributional_oracle_multi\n",
    "        out_dim = 3\n",
    "\n",
    "    noise_vectors = []\n",
    "    for model in models:\n",
    "        model_array = [(torch.tensor(model.weights.reshape(out_dim, -1),\n",
    "                                     dtype=torch.float),\n",
    "                        torch.tensor(model.bias, dtype=torch.float))]\n",
    "        individual = []\n",
    "        for i in range(len(images)):\n",
    "            x = images[i].unsqueeze(0)\n",
    "            y = labels[i]\n",
    "            v = oracle(np.ones(1), model_array, x, y, sys.maxsize)[0]\n",
    "            v = v / v.norm() * noise_budget\n",
    "            individual.append(v)\n",
    "        noise_vectors.append(torch.stack(individual))\n",
    "        \n",
    "    return torch.stack(noise_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_noise_vectors = compute_individual_baseline(models, images, labels, noise_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 100, 784])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_noise_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3000003099441528,\n",
       " 1.3000001907348633,\n",
       " 1.3000001907348633,\n",
       " 1.3000001907348633,\n",
       " 1.3000001907348633]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max([v.norm().item() for v in t]) for t in individual_noise_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Individual Baseline\n",
      "Mean Max [0.7999999999999998, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Individual Baseline\")\n",
    "print(\"Mean Max\", b.compute_best_individual_baseline(models, images, individual_noise_vectors, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate Ascent Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_ascent(models, x, y, noise_budget):\n",
    "    models = subset_feasible_models(models, x, noise_budget)\n",
    "    num_models = len(models)\n",
    "\n",
    "    sol = torch.zeros(x.size())\n",
    "    # can't trick anything\n",
    "    if num_models == 0:\n",
    "        return torch.zeros(x.size())\n",
    "\n",
    "    model_type = type(models[0])\n",
    "    if model_type is BinaryClassifier:\n",
    "        try_region = try_region_binary\n",
    "        labels = [-1, 1]\n",
    "    else:\n",
    "        try_region = try_region_multi\n",
    "        labels = range(3)\n",
    "\n",
    "    x = x.numpy().reshape(-1,)\n",
    "    y = y.item()\n",
    "\n",
    "    label_vector = [y] * num_models  # initialize to the original point, of length feasible_models\n",
    "    label_options = list(set(labels).difference(set([y])))\n",
    "    model_options = list(range(num_models))\n",
    "\n",
    "    for i in range(num_models):\n",
    "        coord = np.random.choice(model_options)\n",
    "        model_options = list(set(model_options).difference([coord]))\n",
    "\n",
    "        label_vector[coord] = np.random.choice(label_options)\n",
    "        v = try_region(models, label_vector, x)\n",
    "\n",
    "        if v is not None:\n",
    "            norm = np.linalg.norm(v)\n",
    "            if norm <= noise_budget:\n",
    "                sol = torch.tensor(v, dtype=torch.float32).reshape(1,-1)\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linear_coordinate_ascent_baseline(models, images, labels, noise_budget):\n",
    "    coordinate_ascent_baseline = []\n",
    "    for i in range(len(images)):\n",
    "        x = images[i].unsqueeze(0)\n",
    "        y = labels[i]\n",
    "        coordinate_ascent_baseline.append(coordinate_ascent(models, x, y, noise_budget))\n",
    "    return torch.stack(coordinate_ascent_baseline).reshape(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_ascent_noise_vectors = compute_linear_coordinate_ascent_baseline(models, images, labels, noise_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2962597608566284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([v.norm().item() for v in coordinate_ascent_noise_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_ascent_accs_per_point = b.compute_model_accs_per_point(models, images, \n",
    "                                                                  coordinate_ascent_noise_vectors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate Ascent Baseline\n",
      "Mean  0.494 Max  0.72\n"
     ]
    }
   ],
   "source": [
    "print(\"Coordinate Ascent Baseline\")\n",
    "print(\"Mean \", np.mean(np.mean(coordinate_ascent_accs_per_point, axis=1)), \n",
    "      \"Max \", np.mean(np.max(coordinate_ascent_accs_per_point, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mwu_accuracies(models, noise_vectors, images, labels):\n",
    "    mwu_iters, num_points = noise_vectors.shape[:2]\n",
    "    model_accs_per_point = []\n",
    "    for i in range(num_points):\n",
    "        x = images[i]\n",
    "        y = labels[i]\n",
    "        model_accs = []\n",
    "        for t in range(mwu_iters):\n",
    "            v = noise_vectors[t][i]\n",
    "            model_accs.append([model.accuracy(x + v, y) for model in models])\n",
    "        model_accs_per_point.append(np.array(model_accs))\n",
    "    \n",
    "    max_acc_plot = []\n",
    "    mean_acc_plot = []\n",
    "    for t in range(mwu_iters):\n",
    "        mean_acc = np.mean([np.mean(np.mean(model_accs[:t+1], axis=0)) for model_accs in model_accs_per_point])\n",
    "        max_acc = np.mean([np.max(np.mean(model_accs[:t+1], axis=0)) for model_accs in model_accs_per_point])\n",
    "        max_acc_plot.append(max_acc)\n",
    "        mean_acc_plot.append(mean_acc)\n",
    "    return {'max':max_acc_plot, 'mean':mean_acc_plot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mwu_oracle = compute_mwu_accuracies(models, experiment_results['binary_oracle']['noise_vectors'],\n",
    "#                                     images, labels)\n",
    "# mwu_pgd = compute_mwu_accuracies(models, experiment_results['binary_pgd']['noise_vectors'],\n",
    "#                                  images, labels)\n",
    "mwu_oracle = compute_mwu_accuracies(models, experiment_results['multi_oracle']['noise_vectors'],\n",
    "                                    images, labels)\n",
    "mwu_pgd = compute_mwu_accuracies(models, experiment_results['multi_pgd']['noise_vectors'],\n",
    "                                 images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Max\n",
      "MWU Oracle  0.13386666666666666 0.16766666666666663\n",
      "MWU PGD  0.34606666666666663 0.5213333333333332\n"
     ]
    }
   ],
   "source": [
    "print('Baseline', 'Mean', 'Max')\n",
    "# print('Individual Baselines', np.mean(individual_baselines_accs), np.max(individual_baselines_accs))\n",
    "# print('Ensemble Baselines', np.mean(ensemble_baselines_accs), np.max(ensemble_baselines_accs))\n",
    "# print('Coordinate Ascent Baselines', np.mean(coordinate_ascent_baseline_accs), np.max(coordinate_ascent_baseline_accs))\n",
    "print('MWU Oracle ', mwu_oracle['mean'][-1], mwu_oracle['max'][-1])\n",
    "print('MWU PGD ', mwu_pgd['mean'][-1], mwu_pgd['max'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mwu_oracle['max'], label='MWU-Oracle')\n",
    "plt.plot(mwu_pgd['max'], label='MWU-PGD')\n",
    "plt.title('Linear Binary')\n",
    "plt.xlabel('MWU Iteration')\n",
    "plt.ylabel('Max Model Accuracy')\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig('binary.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mwu_pgd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in acc_plot:\n",
    "    plt.plot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
